The Kubernetes networking model
relies heavily on IP addresses. Services, pods, containers, and nodes
communicate using IP addresses and ports. Kubernetes provides different types
of load balancing to direct traffic to the correct pod. So let's start by reviewing
basic pod networking. Remember, a pod is a group of containers
with shared storage and networking. This is based on the IP per
pod model of Kubernetes. With this model, each pod is assigned
a single IP address, and the containers within a pod share the same network
namespace, including that IP address. For example, you might have
a legacy application that uses nginx as a reverse proxy for
client access. The nginx container
runs on tcp port 80 and the legacy application
runs on tcp port 8000. Because both containers share
the same networking name space, the two containers appear as though
they are installed on the same machine. The nginx container will contact
the legacy application by establishing a connection to local
host on tcp port 8000. This works well for a single pod, but
your workload doesn't run in single pod. Your workload is composed of
many different applications that need to talk to each other. So how do pods talk to other pods? Each pod has a unique IP address,
just like a host on the network. On a node, the pods are connected to each
other through the node's root network namespace, which ensures that Pods can
find and reach each other on that VM. This allows the two pods to
communicate on the same node. The root network namespace is
connected to the node's primary NIC. Using the nodes VM NIC, the root network namespace is able
to forward traffic out of that node. This means that the IP addresses
on the pods must be routable on the network that
the node is connected to. So where does the node get
the IP address for the pods? In GKE, the nodes will get the pod IP
addresses from address ranges assigned to your Virtual Private Cloud, or VPC. VPCs are logically isolated networks
that provide connectivity for resources you deploy within GCP,
such as Kubernetes clusters, Compute Engine instances, and
App Engine Flex instances. A VPC can be composed of many different IP
subnets in regions all around the world. When you deploy a GKE, you can select
a VPC along with the region or zone. By default,
a VPC has an IP subnet pre-allocated for each GCP region in the world. The IP addresses in the subnet are then
allocated to the compute instances that you deploy in that region. As you learned earlier
in this specialization, GKE cluster nodes are compute instances
that GKE customizes and manages for you. These machines are assigned IP addresses
from the VPC subnet that they reside in. On GCP, alias IPs allow you to configure
additional secondary IP addresses, or IP ranges, on your Compute Engine
virtual machine instances. VPC native GKE clusters
automatically create an alias IP range to reserve approximately
4000 IP addresses for cluster-wide services that
you may create later. This mitigates the problem of unexpectedly
running out of service IP addresses, which, as you'll learn later, your
applications use to talk to one another. VPC-native GKE cluster also creates
a separate alias IP range for your pods. Remember, each pod must
have a unique address. So this address piece will be large. By default,
the address range uses a slash 14 block, which contains over 250,000 IP addresses,
and that's a lot of pods. In reality, Google doesn't expect you to
run 250,000 pods in a single cluster. Instead, that massive IP address range allows GKE to divide the IP
space amongst the nodes. Using this large pod IP range,
GKE locates a much smaller slash 24 block to each node,
which contains about 250 IP addresses. This allows for 1,000 nodes with over
running 100 pods each by default. The number of nodes you expect to use and the maximum number of pods
per node are configurable. So you don't have to reserve
a whole /14 for this. The nodes allocate a unique IP
address from their assigned range to each pod as it starts. As we noted a moment ago, the pods' IP addresses are part of
the address range called an alias IP. GKE automatically configures
your VPC to recognize this range of IP addresses as an authorized
secondary subnet of IP addresses. As a result, the pod's traffic is permitted to pass
the anti-spoofing filters on the network. Also, because each node maintains
a separate IP address base for its pods, the nodes don't need to perform network
address translation on the pod IP addresses. That means that the pods can
directly connect to each other using their native IP addresses. The traffic from your cluster is routed or
peered inside GCP, but becomes now translated, at the node
IP address if it has to exit GCP.